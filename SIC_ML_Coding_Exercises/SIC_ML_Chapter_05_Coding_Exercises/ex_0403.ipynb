{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tn-220/SIC-Machine-Learning/blob/main/SIC_ML_Coding_Exercises/SIC_ML_Chapter_05_Coding_Exercises/ex_0403.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhbUq5GZG8lI"
      },
      "source": [
        "## Coding Exercise #0403"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGiAYtiiG8lT"
      },
      "source": [
        "### 1. Compare clustering algorithms:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMSGwVPzG8lU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from sklearn.datasets import make_blobs, make_moons\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.cluster import AgglomerativeClustering   # merge items into clusters based on distance/similarity\n",
        "from sklearn.cluster import DBSCAN      # Density-based spatial clustering of applications with noise: given a set of points in some space, it groups together points that are closely packed together, marking as outliers points that lie alone in low-density regions\n",
        "\"\"\"\n",
        "Single Linkage: Merge two groups A and B based on their closest pair\n",
        "Ward's Method: Merge the pair of clusters that minimizes the total within-group error (sum of squares) between each document and centroid\n",
        "dendrogram: a diagram representing a tree. in hierarchical clustering, it illustrates the arrangement of the clusters produced by the corresponding analyses\n",
        "fcluster: method forms flat clusters from the hierarchical clustering. It is defined by the given linkage matrix, identifying a link between clustered classes. \n",
        "\"\"\"\n",
        "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vg_itsSZG8lX"
      },
      "source": [
        "#### 1.1. Generate simulated data and visualize:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7v4jSR2mG8lY"
      },
      "outputs": [],
      "source": [
        "# Dataset #1.\n",
        "X1, label1 = make_blobs(n_samples=200, n_features=2, centers=2, cluster_std = 5, random_state=123)\n",
        "plt.scatter(X1[:,0],X1[:,1], c= label1, alpha=0.7 )\n",
        "plt.title('Dataset #1 : Original')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTfmsyhdG8la"
      },
      "outputs": [],
      "source": [
        "# Dataset #2.\n",
        "X2, label2 = make_moons(n_samples=200, noise=0.08, random_state=123)\n",
        "plt.scatter(X2[:,0],X2[:,1], c= label2, alpha=0.7 )\n",
        "plt.title('Dataset #2 : Original')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "carl_JzpG8lc"
      },
      "source": [
        "#### 1.2. Apply k-means clustering and visualize:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCM0jwp7G8le"
      },
      "outputs": [],
      "source": [
        "# Dataset #1 and two clusters.\n",
        "kmeans = KMeans(n_clusters=2,random_state=123)                 # kmeans object for 2 clusters. radom_state=123 means deterministic initialization.\n",
        "kmeans.fit(X1)                                                 # Unsupervised learning => Only X1.    \n",
        "myColors = {0:'red',1:'green'}                                 # Define a color palette: 0~1.\n",
        "plt.scatter(X1[:,0],X1[:,1], c= pd.Series(kmeans.labels_).apply(lambda x: myColors[x]), alpha=0.7 )    \n",
        "plt.title('Dataset #1 : K-Means')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGHPQbo5G8lg"
      },
      "outputs": [],
      "source": [
        "# Dataset #2 and two clusters.\n",
        "kmeans = KMeans(n_clusters=2,random_state=123)                 # kmeans object for 2 clusters. radom_state=123 means deterministic initialization.\n",
        "kmeans.fit(X2)                                                 # Unsupervised learning => Only X1.    \n",
        "myColors = {0:'red',1:'green'}                                 # Define a color palette: 0~1.\n",
        "plt.scatter(X2[:,0],X2[:,1], c= pd.Series(kmeans.labels_).apply(lambda x: myColors[x]), alpha=0.7 )\n",
        "plt.title('Dataset #2 : K-Means')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKFYimAnG8lh"
      },
      "source": [
        "#### 1.3. Apply agglomerative clustering and visualize:\n",
        "\n",
        "AgglomerativeClustering(n_clusters=2, *, affinity='euclidean',..., linkage='ward', ...)\n",
        "\n",
        "\n",
        "linkage{‘ward’, ‘complete’, ‘average’, ‘single’}, default=’ward’\n",
        "\n",
        "The linkage criterion determines which distance to use between sets of observation. The algorithm will merge the pairs of cluster that minimize this criterion.\n",
        "\n",
        "* ‘ward’ minimizes the variance of the clusters being merged.\n",
        "\n",
        "* ‘average’ uses the average of the distances of each observation of the two sets.\n",
        "\n",
        "* ‘complete’ or ‘maximum’ linkage uses the maximum distances between all observations of the two sets.\n",
        "\n",
        "* ‘single’ uses the minimum of the distances between all observations of the two sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBIy0DcYG8ll"
      },
      "outputs": [],
      "source": [
        "# Dataset #1 and two clusters.\n",
        "agglo = AgglomerativeClustering(n_clusters=2)\n",
        "agglo.fit(X1)\n",
        "myColors = {0:'red',1:'green'}                                 # Define a color palette: 0~1.\n",
        "plt.scatter(X1[:,0],X1[:,1], c= pd.Series(agglo.labels_).apply(lambda x: myColors[x]), alpha=0.7 )   \n",
        "plt.title('Dataset #1 : Agglomerative')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXMJLEqAG8ll"
      },
      "outputs": [],
      "source": [
        "# Dataset #2 and two clusters.\n",
        "agglo = AgglomerativeClustering(n_clusters=2)\n",
        "agglo.fit(X2)\n",
        "print(type(agglo))\n",
        "print(type(agglo.labels_))\n",
        "print(np.shape(agglo.labels_))\n",
        "myColors = {0:'red',1:'green'}                                 # Define a color palette: 0~1.\n",
        "plt.scatter(X2[:,0],X2[:,1], c= pd.Series(agglo.labels_).apply(lambda x: myColors[x]), alpha=0.7 )   \n",
        "plt.title('Dataset #2 : Agglomerative')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CC0UP16fG8lm"
      },
      "source": [
        "#### 1.4. Apply hierarchical clustering and visualize: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XzsrE3tG8ln"
      },
      "outputs": [],
      "source": [
        "# Dataset #1 and show dendrogram.\n",
        "# Each new link is the distance between to cluster\n",
        "myLinkage = linkage(X1,method='single')       # Cluster hierarchically using single linkage.\n",
        "print(type(myLinkage))\n",
        "print(np.shape(myLinkage))\n",
        "print(np.shape(X1))\n",
        "\n",
        "plt.figure(figsize=(20,5))\n",
        "dendrogram(myLinkage)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IL74fwSG8ln"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "    fcluster : Form flat clusters from the hierarchical clustering defined by the given linkage matrix.\n",
        "\"\"\"\n",
        "# Dataset #1 and clusters by cutting the dendrogram.\n",
        "labels = fcluster(myLinkage, 4, criterion='distance')                      #  Cut at the height (distance) = 4 <= change this value at will.\n",
        "print(np.shape(labels))\n",
        "print(labels)\n",
        "pd.Series(labels).value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cj2sdiOuG8lo"
      },
      "outputs": [],
      "source": [
        "# Dataset #2 and show dendrogram.\n",
        "myLinkage = linkage(X2,method='single')       # Cluster hierarchically using single linkage.\n",
        "plt.figure(figsize=(20,5))\n",
        "dendrogram(myLinkage)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WB5sBA1VG8lp"
      },
      "outputs": [],
      "source": [
        "# Dataset #2 and clusters by cutting the dendrogram.\n",
        "labels = fcluster(myLinkage, 0.23, criterion='distance')                      #  Cut at the height (distance) = 0.23 <= change this value at will.\n",
        "print(pd.Series(labels).value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1HE5O77G8lp"
      },
      "outputs": [],
      "source": [
        "myColors = {1:'red',2:'green'}                                                # Define a color palette: 1~2.\n",
        "plt.scatter(X2[:,0],X2[:,1], c= pd.Series(labels).apply(lambda x: myColors[x]), alpha=0.7 )   \n",
        "plt.title('Dataset #2 : Hierarchical')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G09P2LktG8lp"
      },
      "source": [
        "#### 1.5. Apply DBSCAN and visualize: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2VNqr24G8lq"
      },
      "outputs": [],
      "source": [
        "# Dataset #1.\n",
        "# eps: The maximum distance between two samples for one to be considered as in the neighborhood of the other. \n",
        "\"\"\"\n",
        "  a core sample is defined as being a sample in the dataset such that there exist min_samples \n",
        "  other samples within a distance of eps, which are defined as neighbors of the core sample.\n",
        "\"\"\"\n",
        "dbscan = DBSCAN(eps=2, min_samples=5)\n",
        "dbscan.fit(X1)      # noise is clustered as -1\n",
        "print(dbscan.labels_)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dbscan = DBSCAN(eps=5, min_samples=5)\n",
        "dbscan.fit(X1) \n",
        "print(dbscan.labels_)\n",
        "myColors = {-1:'red',0:'green',1:'blue'}                                 # Define a color palette: -1~1.  Red = -1 = outlier.\n",
        "plt.scatter(X1[:,0],X1[:,1], c= pd.Series(dbscan.labels_).apply(lambda x: myColors[x]), alpha=0.7 )   \n",
        "plt.title('Dataset #1 : DBSCAN')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0XETfx4t-fBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rrXtixLG8lr"
      },
      "outputs": [],
      "source": [
        "# Dataset #2.\n",
        "dbscan = DBSCAN(eps=0.2, min_samples=5)\n",
        "dbscan.fit(X2)\n",
        "myColors = {-1:'red',0:'green',1:'blue'}                                 # Define a color palette: -1~1. Red = -1 = outlier.\n",
        "plt.scatter(X2[:,0],X2[:,1], c= pd.Series(dbscan.labels_).apply(lambda x: myColors[x]), alpha=0.7 )   \n",
        "plt.title('Dataset #2 : DBSCAN')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGx5oJxMG8lt"
      },
      "source": [
        "NOTE: Let's discuss the result of the different clustering algorithms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Kbm8NFoG8lu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}